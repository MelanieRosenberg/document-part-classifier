<TABLE>
Day                       Week
                 Features                        NDCG@10      NDCG@7       NDCG@35      NDCG@70
                 Metadata (excluding hasPR)        0.4114       0.4513       0.4460       0.4068
                 Metadata                          0.5485       0.6758       0.6148       0.5740
                 Metadata + Title                  0.6112       0.7615       0.6778       0.6097
All Articles     Metadata + Abstract               0.6116       0.7935       0.6920       0.6284
                 Metadata + Press Release          0.5957       0.7563       0.6943       0.6344
                 Metadata + Title + Abstract       0.6114       0.8236       0.6944       0.6280
                 Metadata + Title + Press Release  0.6209       0.8107       0.7282       0.6472
                 Title + Abstract + Press Release  0.6273       0.8868       0.7076       0.6416
                 All Features                      0.6354       0.8841       0.7313       0.6621
                 Metadata                          0.5101       0.4775       0.4433       0.5307
                 Metadata + Title                  0.5362       0.4782       0.4584       0.5259
                 Metadata + Abstract               0.5611       0.5629       0.5085       0.5721
Conditioned on   Metadata + Press Release          0.5841       0.6015       0.5315       0.6009
 Press Release   Metadata + Title + Abstract       0.5657       0.6020       0.4936       0.5597
                 Metadata + Title + Press Release  0.5888       0.6036       0.5350       0.6050
                 Title + Abstract + Press Release  0.5902       0.5526       0.5251       0.5904
                 All Features                      0.6065       0.6156       0.5559       0.6106
</TABLE>
<SECTION_HEADER>
5 Results
</SECTION_HEADER>
<TEXT>
We present results on three tasks. The first two tasks are ranking ones. In task one, we attempt to learn to rank lists of scientific articles grouped by day. In task two, we per- form the same task, but on lists of scientific articles grouped by week. For task three, we consider the binary task of dif- ferentiating between scientific articles with real coverage and those with coverage only from press release issuers and copiers.
</TEXT>
<SECTION_HEADER>
5.1 Daily Prediction
</SECTION_HEADER>
<TEXT>
SeeTable3 forresultsforthis experiment.Inlinewith previ- ous research, textual bag-of-words features provide baseline performance higher than just metadata features. The model using all features performs the best, but it does not statisti- cally significantly outperform models using all textual fea- tures or metadata, title and press release features.
</TEXT>
<TEXT>
Table 4 lists the top features for the best performing fea- ture set, all features. Due to the nonlinear nature of gradient boosted trees, we are unable to exactly determine the po- larity of different features, only their importances, given by the number of times on which they were split. We approxi- mate feature polarity by the difference in average relevance of documents with and without each feature.
</TEXT>
<TEXT>
To note, interpretation of these features, especially single features, is highly conjectural. Regardless, we provide some discussion and speculation. As expected, coverage on Eu- rekAlert! or Science Daily is very predictive, as are gener- ally popular and unpopular subjects such as medicine (pop- ular) and chemistry (unpopular). As can be seen in table 4,
</TEXT>
<CAPTION>
journal journal subj scopus subj publisher abstract
</CAPTION>
<UNSPECIFIED>
# Split Polarity Feature Source 100 0.57 hasPR hasPR 88 1.31 mesothelioma abstract 85 0.44 patients press release 83 -0.21 life sciences scopus subj 70 -0.37 alzheimer abstract 61 0.16 years abstract 54 0.65 health information crossref subj management 48 0.82 Massachusetts publisher Medical Society 46 0.18 95 abstract 42 0.31 The Royal Society publisher 41 0.62 people press release 39 0.59 years press release 38 0.65 zika virus title 35 0.20 science journal subj 33 0.00 agricultural and scopus subj biological sciences 32 0.61 Science Advances 31 0.19 medicine 31 -0.20 chemistry 30 0.14 Elsevier 30 0.13 evidence
</UNSPECIFIED>
<UNSPECIFIED>
Table 3: Daily  and weekly  popularity  prediction: results on all articles then conditioning on press release issuance. Metadata
features include hasPR,  subjects, journal and  publisher. After conditioning on  press release issuance, there are some  days  on
which  fewer  than 10  scientific articles were published - for those days  NDCG    is calculated up to that number   of scientific
articles. Best result for each column is in bold. Models in each column   that the respective best performing model  significantly
outperforms  are italicized (p < 0.05, permutation test).
</UNSPECIFIED>
<PAGE_BREAK>
