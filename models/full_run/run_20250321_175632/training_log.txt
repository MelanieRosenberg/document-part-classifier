2025-03-21 17:56:32,849 - INFO - Loading datasets...
2025-03-21 17:56:32,871 - INFO - Number of training examples: 12780
2025-03-21 17:56:32,871 - INFO - Number of validation examples: 12780
2025-03-21 17:56:34,761 - INFO - 
Class weights:
2025-03-21 17:56:34,761 - INFO - FORM: 2.0000
2025-03-21 17:56:34,761 - INFO -   ^ Primary tag, weight multiplied by 2.0
2025-03-21 17:56:34,761 - INFO - TABLE: 2.0000
2025-03-21 17:56:34,761 - INFO -   ^ Primary tag, weight multiplied by 2.0
2025-03-21 17:56:34,761 - INFO - TEXT: 2.0000
2025-03-21 17:56:34,761 - INFO -   ^ Primary tag, weight multiplied by 2.0
2025-03-21 17:56:43,064 - INFO - Total training steps: 15980
2025-03-21 17:56:43,064 - INFO - Warmup steps: 1598
2025-03-21 18:00:15,638 - INFO - Step 100/1598: Train Loss: 1.1537, LR: 1.25e-06
2025-03-21 18:03:47,190 - INFO - Step 200/1598: Train Loss: 1.1288, LR: 2.50e-06
2025-03-21 18:07:16,184 - INFO - Step 300/1598: Train Loss: 1.1154, LR: 3.75e-06
2025-03-21 18:10:44,673 - INFO - Step 400/1598: Train Loss: 1.1033, LR: 5.01e-06
2025-03-21 18:14:11,218 - INFO - Step 500/1598: Train Loss: 1.0859, LR: 6.26e-06
2025-03-21 18:18:04,882 - INFO - Step 600/1598: Train Loss: 1.0521, LR: 7.51e-06
2025-03-21 18:21:20,774 - INFO - Step 700/1598: Train Loss: 0.9921, LR: 8.76e-06
2025-03-21 18:24:53,408 - INFO - Step 800/1598: Train Loss: 0.9447, LR: 1.00e-05
2025-03-21 18:28:22,203 - INFO - Step 900/1598: Train Loss: 0.9074, LR: 1.13e-05
2025-03-21 18:32:02,013 - INFO - Step 1000/1598: Train Loss: 0.8717, LR: 1.25e-05
2025-03-21 18:35:24,443 - INFO - Step 1100/1598: Train Loss: 0.8423, LR: 1.38e-05
2025-03-21 18:38:41,746 - INFO - Step 1200/1598: Train Loss: 0.8095, LR: 1.50e-05
2025-03-21 18:41:48,097 - INFO - Step 1300/1598: Train Loss: 0.7857, LR: 1.63e-05
2025-03-21 18:44:55,696 - INFO - Step 1400/1598: Train Loss: 0.7678, LR: 1.75e-05
2025-03-21 18:48:04,620 - INFO - Step 1500/1598: Train Loss: 0.7504, LR: 1.88e-05
2025-03-21 18:51:07,913 - INFO - Epoch 1/10 - Train Loss: 0.7334
2025-03-21 19:30:00,979 - INFO - Epoch 1/10 - Validation Loss: 0.4382
2025-03-21 19:30:00,980 - INFO - FORM: Precision: 0.6846, Recall: 0.8282, F1: 0.7496
2025-03-21 19:30:00,980 - INFO - TABLE: Precision: 0.8370, Recall: 0.7279, F1: 0.7787
2025-03-21 19:30:00,980 - INFO - TEXT: Precision: 0.9370, Recall: 0.8627, F1: 0.8983
2025-03-21 19:30:00,980 - INFO - New best validation loss: 0.4382! Saving model...
2025-03-21 19:33:29,537 - INFO - Step 100/1598: Train Loss: 0.4531, LR: 1.99e-05
2025-03-21 19:36:56,391 - INFO - Step 200/1598: Train Loss: 0.4500, LR: 1.97e-05
2025-03-21 19:40:05,734 - INFO - Step 300/1598: Train Loss: 0.4607, LR: 1.96e-05
2025-03-21 19:43:12,126 - INFO - Step 400/1598: Train Loss: 0.4626, LR: 1.94e-05
2025-03-21 19:46:17,986 - INFO - Step 500/1598: Train Loss: 0.4614, LR: 1.93e-05
2025-03-21 19:49:23,582 - INFO - Step 600/1598: Train Loss: 0.4701, LR: 1.92e-05
2025-03-21 19:52:32,422 - INFO - Step 700/1598: Train Loss: 0.4737, LR: 1.90e-05
2025-03-21 19:55:49,839 - INFO - Step 800/1598: Train Loss: 0.4676, LR: 1.89e-05
2025-03-21 19:59:02,063 - INFO - Step 900/1598: Train Loss: 0.4661, LR: 1.87e-05
2025-03-21 20:02:18,679 - INFO - Step 1000/1598: Train Loss: 0.4669, LR: 1.86e-05
2025-03-21 20:05:23,570 - INFO - Step 1100/1598: Train Loss: 0.4668, LR: 1.85e-05
2025-03-21 20:08:31,709 - INFO - Step 1200/1598: Train Loss: 0.4641, LR: 1.83e-05
2025-03-21 20:11:41,322 - INFO - Step 1300/1598: Train Loss: 0.4621, LR: 1.82e-05
2025-03-21 20:14:43,459 - INFO - Step 1400/1598: Train Loss: 0.4616, LR: 1.81e-05
2025-03-21 20:17:44,226 - INFO - Step 1500/1598: Train Loss: 0.4587, LR: 1.79e-05
2025-03-21 20:20:39,913 - INFO - Epoch 2/10 - Train Loss: 0.4558
2025-03-21 20:56:05,207 - INFO - Epoch 2/10 - Validation Loss: 0.3049
2025-03-21 20:56:05,207 - INFO - FORM: Precision: 0.7379, Recall: 0.9188, F1: 0.8185
2025-03-21 20:56:05,207 - INFO - TABLE: Precision: 0.9224, Recall: 0.8012, F1: 0.8575
2025-03-21 20:56:05,207 - INFO - TEXT: Precision: 0.9648, Recall: 0.8552, F1: 0.9067
2025-03-21 20:56:05,208 - INFO - New best validation loss: 0.3049! Saving model...
2025-03-21 20:59:19,356 - INFO - Step 100/1598: Train Loss: 0.3302, LR: 1.76e-05
2025-03-21 21:02:33,340 - INFO - Step 200/1598: Train Loss: 0.3440, LR: 1.75e-05
2025-03-21 21:05:39,241 - INFO - Step 300/1598: Train Loss: 0.3547, LR: 1.74e-05
2025-03-21 21:08:51,417 - INFO - Step 400/1598: Train Loss: 0.3642, LR: 1.72e-05
2025-03-21 21:12:00,663 - INFO - Step 500/1598: Train Loss: 0.3646, LR: 1.71e-05
2025-03-21 21:15:03,274 - INFO - Step 600/1598: Train Loss: 0.3661, LR: 1.69e-05
2025-03-21 21:18:07,269 - INFO - Step 700/1598: Train Loss: 0.3642, LR: 1.68e-05
2025-03-21 21:21:07,248 - INFO - Step 800/1598: Train Loss: 0.3650, LR: 1.67e-05
2025-03-21 21:24:07,574 - INFO - Step 900/1598: Train Loss: 0.3657, LR: 1.65e-05
2025-03-21 21:27:11,037 - INFO - Step 1000/1598: Train Loss: 0.3678, LR: 1.64e-05
2025-03-21 21:30:12,569 - INFO - Step 1100/1598: Train Loss: 0.3716, LR: 1.62e-05
2025-03-21 21:33:16,830 - INFO - Step 1200/1598: Train Loss: 0.3702, LR: 1.61e-05
2025-03-21 21:36:15,879 - INFO - Step 1300/1598: Train Loss: 0.3681, LR: 1.60e-05
2025-03-21 21:39:17,565 - INFO - Step 1400/1598: Train Loss: 0.3640, LR: 1.58e-05
2025-03-21 21:42:26,055 - INFO - Step 1500/1598: Train Loss: 0.3653, LR: 1.57e-05
2025-03-21 21:45:42,118 - INFO - Epoch 3/10 - Train Loss: 0.3625
2025-03-21 22:24:40,881 - INFO - Epoch 3/10 - Validation Loss: 0.2693
2025-03-21 22:24:40,882 - INFO - FORM: Precision: 0.9913, Recall: 0.7725, F1: 0.8683
2025-03-21 22:24:40,882 - INFO - TABLE: Precision: 0.8503, Recall: 0.8934, F1: 0.8713
2025-03-21 22:24:40,882 - INFO - TEXT: Precision: 0.8136, Recall: 0.9519, F1: 0.8773
2025-03-21 22:24:40,882 - INFO - New best validation loss: 0.2693! Saving model...
2025-03-21 22:28:05,422 - INFO - Step 100/1598: Train Loss: 0.2441, LR: 1.54e-05
2025-03-22 07:32:00,649 - INFO - Step 200/1598: Train Loss: 0.2582, LR: 1.53e-05
2025-03-22 09:58:15,161 - INFO - Step 300/1598: Train Loss: 0.2760, LR: 1.51e-05
2025-03-22 10:01:48,903 - INFO - Step 400/1598: Train Loss: 0.2757, LR: 1.50e-05
2025-03-22 10:05:19,612 - INFO - Step 500/1598: Train Loss: 0.2776, LR: 1.49e-05
2025-03-22 10:09:02,806 - INFO - Step 600/1598: Train Loss: 0.2757, LR: 1.47e-05
2025-03-22 10:12:40,109 - INFO - Step 700/1598: Train Loss: 0.2721, LR: 1.46e-05
2025-03-22 10:16:16,315 - INFO - Step 800/1598: Train Loss: 0.2773, LR: 1.44e-05
2025-03-22 10:19:53,905 - INFO - Step 900/1598: Train Loss: 0.2784, LR: 1.43e-05
2025-03-22 10:23:43,349 - INFO - Step 1000/1598: Train Loss: 0.2776, LR: 1.42e-05
2025-03-22 10:27:14,681 - INFO - Step 1100/1598: Train Loss: 0.2825, LR: 1.40e-05
2025-03-22 10:30:43,807 - INFO - Step 1200/1598: Train Loss: 0.2830, LR: 1.39e-05
2025-03-22 10:34:10,191 - INFO - Step 1300/1598: Train Loss: 0.2822, LR: 1.37e-05
2025-03-22 10:37:45,008 - INFO - Step 1400/1598: Train Loss: 0.2838, LR: 1.36e-05
2025-03-22 10:41:17,196 - INFO - Step 1500/1598: Train Loss: 0.2876, LR: 1.35e-05
2025-03-22 10:44:49,805 - INFO - Epoch 4/10 - Train Loss: 0.2911
2025-03-22 11:23:01,874 - INFO - Epoch 4/10 - Validation Loss: 0.2385
2025-03-22 11:23:01,875 - INFO - FORM: Precision: 0.9165, Recall: 0.8481, F1: 0.8810
2025-03-22 11:23:01,875 - INFO - TABLE: Precision: 0.8281, Recall: 0.9275, F1: 0.8750
2025-03-22 11:23:01,875 - INFO - TEXT: Precision: 0.9262, Recall: 0.8843, F1: 0.9048
2025-03-22 11:23:01,875 - INFO - New best validation loss: 0.2385! Saving model...
2025-03-22 11:26:37,299 - INFO - Step 100/1598: Train Loss: 0.2973, LR: 1.32e-05
2025-03-22 11:30:12,851 - INFO - Step 200/1598: Train Loss: 0.2852, LR: 1.31e-05
2025-03-22 11:33:32,216 - INFO - Step 300/1598: Train Loss: 0.2766, LR: 1.29e-05
2025-03-22 11:36:53,126 - INFO - Step 400/1598: Train Loss: 0.2768, LR: 1.28e-05
2025-03-22 11:40:05,209 - INFO - Step 500/1598: Train Loss: 0.2714, LR: 1.26e-05
2025-03-22 11:43:19,602 - INFO - Step 600/1598: Train Loss: 0.2608, LR: 1.25e-05
2025-03-22 11:46:38,082 - INFO - Step 700/1598: Train Loss: 0.2576, LR: 1.24e-05
2025-03-22 11:49:47,504 - INFO - Step 800/1598: Train Loss: 0.2577, LR: 1.22e-05
2025-03-22 11:52:58,282 - INFO - Step 900/1598: Train Loss: 0.2528, LR: 1.21e-05
2025-03-22 11:56:12,315 - INFO - Step 1000/1598: Train Loss: 0.2515, LR: 1.19e-05
2025-03-22 11:59:20,475 - INFO - Step 1100/1598: Train Loss: 0.2524, LR: 1.18e-05
2025-03-22 12:02:34,843 - INFO - Step 1200/1598: Train Loss: 0.2509, LR: 1.17e-05
2025-03-22 12:05:44,059 - INFO - Step 1300/1598: Train Loss: 0.2573, LR: 1.15e-05
2025-03-22 12:08:48,318 - INFO - Step 1400/1598: Train Loss: 0.2565, LR: 1.14e-05
2025-03-22 12:12:02,291 - INFO - Step 1500/1598: Train Loss: 0.2596, LR: 1.12e-05
2025-03-22 12:15:08,950 - INFO - Epoch 5/10 - Train Loss: 0.2594
2025-03-22 12:52:34,266 - INFO - Epoch 5/10 - Validation Loss: 0.1891
2025-03-22 12:52:34,267 - INFO - FORM: Precision: 0.7757, Recall: 0.9880, F1: 0.8691
2025-03-22 12:52:34,267 - INFO - TABLE: Precision: 0.9846, Recall: 0.8573, F1: 0.9166
2025-03-22 12:52:34,267 - INFO - TEXT: Precision: 0.9942, Recall: 0.8507, F1: 0.9169
2025-03-22 12:52:34,268 - INFO - New best validation loss: 0.1891! Saving model...
2025-03-22 12:55:45,981 - INFO - Step 100/1598: Train Loss: 0.2363, LR: 1.10e-05
2025-03-22 12:58:50,943 - INFO - Step 200/1598: Train Loss: 0.2231, LR: 1.08e-05
2025-03-22 13:02:02,279 - INFO - Step 300/1598: Train Loss: 0.2172, LR: 1.07e-05
2025-03-22 13:05:03,555 - INFO - Step 400/1598: Train Loss: 0.2162, LR: 1.06e-05
2025-03-22 13:08:26,234 - INFO - Step 500/1598: Train Loss: 0.2269, LR: 1.04e-05
2025-03-22 13:11:35,129 - INFO - Step 600/1598: Train Loss: 0.2273, LR: 1.03e-05
2025-03-22 13:14:50,996 - INFO - Step 700/1598: Train Loss: 0.2351, LR: 1.01e-05
2025-03-22 13:18:13,402 - INFO - Step 800/1598: Train Loss: 0.2350, LR: 1.00e-05
2025-03-22 13:21:36,643 - INFO - Step 900/1598: Train Loss: 0.2381, LR: 9.86e-06
2025-03-22 13:24:53,499 - INFO - Step 1000/1598: Train Loss: 0.2368, LR: 9.72e-06
2025-03-22 13:28:14,269 - INFO - Step 1100/1598: Train Loss: 0.2340, LR: 9.58e-06
2025-03-22 13:31:36,150 - INFO - Step 1200/1598: Train Loss: 0.2336, LR: 9.44e-06
2025-03-22 13:35:02,204 - INFO - Step 1300/1598: Train Loss: 0.2315, LR: 9.30e-06
2025-03-22 13:38:26,348 - INFO - Step 1400/1598: Train Loss: 0.2293, LR: 9.16e-06
2025-03-22 13:42:01,500 - INFO - Step 1500/1598: Train Loss: 0.2311, LR: 9.03e-06
2025-03-22 13:45:24,322 - INFO - Epoch 6/10 - Train Loss: 0.2310
